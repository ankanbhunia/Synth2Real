{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "!pip install moviepy\n",
    "from fcn8s_tensorflow import FCN8s\n",
    "from data_generator.batch_generator import BatchGenerator\n",
    "from helpers.visualization_utils import print_segmentation_onto_image, create_video_from_images\n",
    "from cityscapesscripts.helpers.labels import TRAINIDS_TO_COLORS_DICT, TRAINIDS_TO_RGBA_DICT\n",
    "\n",
    "from math import ceil\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set the paths to the images.\n",
    "train_images_synth = '/content/Synth2Real/Synthetic/Images/'\n",
    "\n",
    "\n",
    "# TODO: Set the paths to the ground truth images.\n",
    "train_gt_synth = '/content/Synth2Real/Synthetic/Labels/'\n",
    "\n",
    "# TODO: Set the paths to the images.\n",
    "train_images_real = '/content/Synth2Real/Real/Images/'\n",
    "\n",
    "\n",
    "# TODO: Set the paths to the ground truth images.\n",
    "train_gt_real = '/content/Synth2Real/Real/Labels/'\n",
    "\n",
    "\n",
    "test_images = '/content/Synth2Real/test/Images/'\n",
    "\n",
    "test_gt = '/content/Synth2Real/test/Labels/'\n",
    "\n",
    "num_classes = 34 # TODO: Set the number of segmentation classes.\n",
    "\n",
    "train_dataset_real = BatchGenerator(image_dirs=train_images_real,\n",
    "                               image_file_extension='png',\n",
    "                               ground_truth_dirs=train_gt_real,\n",
    "                               image_name_split_separator='leftImg8bit',\n",
    "                               ground_truth_suffix='gtFine_labelIds',\n",
    "                               check_existence=True,\n",
    "                               num_classes=num_classes)\n",
    "\n",
    "train_dataset = [train_dataset_real]\n",
    "\n",
    "val_dataset = BatchGenerator(image_dirs=test_images,\n",
    "                             image_file_extension='png',\n",
    "                             ground_truth_dirs=test_gt,\n",
    "                             image_name_split_separator='leftImg8bit',\n",
    "                             ground_truth_suffix='gtFine_labelIds',\n",
    "                             check_existence=True,\n",
    "                             num_classes=num_classes)\n",
    "\n",
    "num_train_images = train_dataset[0].get_num_files() \n",
    "num_val_images = val_dataset.get_num_files()\n",
    "\n",
    "print(\"Size of training dataset: \", num_train_images, \" images\")\n",
    "print(\"Size of validation dataset: \", num_val_images, \" images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set the batch size. I'll use the same batch size for both generators here.\n",
    "batch_size = 4\n",
    "\n",
    "train_generator = []\n",
    "\n",
    "train_generator.append(train_dataset[0].generate(batch_size=batch_size,\n",
    "                                         convert_colors_to_ids=False,\n",
    "                                         convert_ids_to_ids=False,\n",
    "                                         convert_to_one_hot=True,\n",
    "                                         void_class_id=None,\n",
    "                                         random_crop=False,\n",
    "                                         crop=False,\n",
    "                                         resize=False,\n",
    "                                         brightness=False,\n",
    "                                         flip=0.5,\n",
    "                                         translate=False,\n",
    "                                         scale=False,\n",
    "                                         gray=False,\n",
    "                                         to_disk=False,\n",
    "                                         shuffle=True))\n",
    "\n",
    "val_generator = val_dataset.generate(batch_size=batch_size,\n",
    "                                     convert_colors_to_ids=False,\n",
    "                                     convert_ids_to_ids=False,\n",
    "                                     convert_to_one_hot=True,\n",
    "                                     void_class_id=None,\n",
    "                                     random_crop=False,\n",
    "                                     crop=False,\n",
    "                                     resize=False,\n",
    "                                     brightness=False,\n",
    "                                     flip=False,\n",
    "                                     translate=False,\n",
    "                                     scale=False,\n",
    "                                     gray=False,\n",
    "                                     to_disk=False,\n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = FCN8s(model_load_dir=None,\n",
    "              tags=None,\n",
    "              vgg16_dir='/content/VGG-16_mod2FCN_ImageNet-Classification',\n",
    "              num_classes=num_classes,\n",
    "              variables_load_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200 # TODO: Set the number of epochs to train for.\n",
    "\n",
    "# TODO: Define a learning rate schedule function to be passed to the `train()` method.\n",
    "def learning_rate_schedule(step):\n",
    "    if step <= 10000: return 0.0001\n",
    "    elif 10000 < step <= 20000: return 0.00001\n",
    "    elif 20000 < step <= 40000: return 0.000003\n",
    "    else: return 0.000001\n",
    "    \n",
    "model.train(train_generator=train_generator,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=ceil(num_train_images/batch_size),\n",
    "            learning_rate_schedule=learning_rate_schedule,\n",
    "            keep_prob=0.5,\n",
    "            l2_regularization=0.0,\n",
    "            eval_dataset='val',\n",
    "            eval_frequency=1,\n",
    "            val_generator=val_generator,\n",
    "            val_steps=ceil(num_val_images/batch_size),\n",
    "            metrics={'loss', 'mean_iou', 'accuracy'},\n",
    "            save_during_training=True,\n",
    "            save_dir='only_real',\n",
    "            save_best_only=True,\n",
    "            save_tags=['default'],\n",
    "            save_name='(batch-size-4)',\n",
    "            save_frequency=2,\n",
    "            saver='saved_model',\n",
    "            monitor='loss',\n",
    "            record_summaries=True,\n",
    "            summaries_frequency=10,\n",
    "            summaries_dir='tensorboard_log/only_real',\n",
    "            summaries_name='configuration_01',\n",
    "            training_loss_display_averaging=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(data_generator=val_generator,\n",
    "               metrics={'loss', 'mean_iou', 'accuracy'},\n",
    "               num_batches=ceil(num_val_images/batch_size),\n",
    "               l2_regularization=0.0,\n",
    "               dataset='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # Select which image of the batch you would like to visualize.\n",
    "\n",
    "# Make a prediction.\n",
    "prediction = model.predict([images[n]], argmax=False)\n",
    "\n",
    "# Print the predicted segmentation onto the image.\n",
    "segmented_image = print_segmentation_onto_image(images[n], prediction, color_map=TRAINIDS_TO_RGBA_DICT)\n",
    "\n",
    "plt.figure(figsize=(20,14))\n",
    "plt.imshow(segmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
