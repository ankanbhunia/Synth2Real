{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a63b578e1c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground_truth_conversion_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_IDs_to_IDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_IDs_to_one_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBatchGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helpers'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import scipy.misc\n",
    "import cv2\n",
    "from glob import glob\n",
    "from math import ceil\n",
    "from tqdm import trange\n",
    "\n",
    "from helpers.ground_truth_conversion_utils import convert_IDs_to_IDs, convert_IDs_to_one_hot\n",
    "\n",
    "class BatchGenerator():\n",
    "\n",
    "    def __init__(self,\n",
    "                 image_dirs,\n",
    "                 image_file_extension='png',\n",
    "                 ground_truth_dirs=None,\n",
    "                 image_name_split_separator=None,\n",
    "                 ground_truth_suffix=None,\n",
    "                 check_existence=True,\n",
    "                 num_classes=None,\n",
    "                 root_dir=None,\n",
    "                 export_dir=None):\n",
    "        '''\n",
    "        Arguments:\n",
    "            image_dirs (list): A list of directory paths, each of which contain\n",
    "                images either directly or within a hierarchy of subdirectories.\n",
    "                The directory paths given serve as root directories and the generator\n",
    "                will load images from all subdirectories within. This lets you\n",
    "                combine multiple datasets randomly. All images must have 3 channels.\n",
    "            image_file_extension (string, optional): The file extension of the\n",
    "                images in the datasets. Must be identical for all images in all\n",
    "                datasets in `datasets`. Defaults to `png`.\n",
    "            ground_truth_dirs (list, optional): `None` or a list of directory paths,\n",
    "                each of which contain the ground truth images that correspond to\n",
    "                the respective directory paths in `datasets`. The ground truth\n",
    "                images must have 1 channel that encodes the segmentation classes\n",
    "                numbered consecutively from 0 to `n`, where `n` is an integer.\n",
    "            image_name_split_separator (string, optional): Only relevant if\n",
    "                `ground_truth_dirs` contains at least one item. A string by which\n",
    "                the image names will be split into a left and right part, the left\n",
    "                part of which (i.e. the beginning of the image file name) will be\n",
    "                used to get the matching ground truth image file name. More precisely,\n",
    "                all characters left of the separator string will constitute the\n",
    "                beginning of the file name of the corresponding ground truth image.\n",
    "            ground_truth_suffix (string, optional): The suffix added to the left part of\n",
    "                an image name string (see `image_name_split_separator`) in order\n",
    "                to compose the name of the corresponding ground truth image file.\n",
    "                The suffix must exclude the file extension.\n",
    "            check_existence (bool, optional): Only relevant if ground truth images\n",
    "                are given. If `True`, the constructor checks for each ground truth image\n",
    "                path whether the respective file actually exists and throws a\n",
    "                `DataError` if it doesn't. Defaults to `True`.\n",
    "            num_classes (int, optional): The number of segmentation classes in the\n",
    "                ground truth data. Only relevant if you want the generator to convert\n",
    "                numeric labels to one-hot format, otherwise you can leave this `None`.\n",
    "            root_dir (string, optional): The dataset root directory. This is only\n",
    "                relevant if you want to use the generator to save processed data\n",
    "                to disk in addition to yielding it, i.e. if you want to do offline processing.\n",
    "                In this case, the generator will reproduce the directory hierarchy\n",
    "                of the source data within the target directory in which to save\n",
    "                the processed data. It needs to know the root directory of the\n",
    "                dataset in order to do so\n",
    "            export_dir (string, optional): This is only relevant if you want use\n",
    "                the generator to save processed data to disk in addition to yielding it,\n",
    "                i.e. if you want to do offline processing. This is the directory\n",
    "                into which the processed data will be written. The generator will\n",
    "                reproduce the directory hierarchy of the source data within this\n",
    "                directory.\n",
    "        '''\n",
    "\n",
    "        self.image_dirs = image_dirs\n",
    "        self.ground_truth_dirs = ground_truth_dirs\n",
    "        self.root_dir = root_dir # The dataset root directory.\n",
    "        self.export_dir = export_dir\n",
    "        self.image_paths = [] # The list of images from which the generator will draw.\n",
    "        self.ground_truth_paths = {} # The dictionary of ground truth images that correspond to the images.\n",
    "        self.num_classes = num_classes\n",
    "        self.dataset_size = 0\n",
    "        self.ground_truth = False # Whether or not ground truth images were given.\n",
    "\n",
    "        if (not self.ground_truth_dirs is None) and (len(self.image_dirs) != len(self.ground_truth_dirs)):\n",
    "            raise ValueError(\"`image_dirs` and `ground_truth_dirs` must contain the same number of elements.\")\n",
    "\n",
    "        image_file_extension = image_file_extension.lower()\n",
    "\n",
    "        for i, image_dir in enumerate(image_dirs): # Iterate over all given datasets.\n",
    "\n",
    "            for image_dir_path, subdir_list, file_list in os.walk(image_dir, topdown=True): # Iterate over all subdirectories of this dataset directory.\n",
    "\n",
    "                image_paths = glob(os.path.join(image_dir_path, '*.' + image_file_extension)) # Get all images in this directory\n",
    "\n",
    "                if len(image_paths) > 0: # If there are any images, add them to the list of images.\n",
    "\n",
    "                    self.image_paths += image_paths\n",
    "\n",
    "                    if not ground_truth_dirs is None: # If there is ground truth data, add it to the ground truth list.\n",
    "                        # Get the path of the ground truth directory that corresponds to this image directory.\n",
    "                        ground_truth_dir = ground_truth_dirs[i] # Get the head.\n",
    "                        ground_truth_subdir = os.path.basename(os.path.normpath(image_dir_path)) # Get the subdirectory we're currently in.\n",
    "                        ground_truth_dir_path = os.path.join(ground_truth_dir, ground_truth_subdir)\n",
    "\n",
    "                        # Loop over all image paths to collect the corresponding ground truth image paths.\n",
    "                        for image_path in image_paths:\n",
    "                            # Construct the name of the ground truth image from the name of the image.\n",
    "                            image_name = os.path.basename(image_path)\n",
    "                            left_part = image_name.split(image_name_split_separator, 1)[0] # Get the left part of the split.\n",
    "                            # Compose the name of the ground truth image that corresponds to this image.\n",
    "                            ground_truth_image_name = left_part + ground_truth_suffix + '.' + image_file_extension\n",
    "                            # Create the full path to this ground truth image.\n",
    "                            ground_truth_path = os.path.join(ground_truth_dir_path, ground_truth_image_name)\n",
    "\n",
    "                            if check_existence and not os.path.isfile(ground_truth_path):\n",
    "                                raise DataError(\"The dataset contains an image file '{}' for which the corresponding ground truth image file does not exist at '{}'.\".format(image_path, ground_truth_path))\n",
    "\n",
    "                            # Add the pair `image_name : ground_truth_path` to the dictionary\n",
    "                            self.ground_truth_paths[image_name] = ground_truth_path\n",
    "\n",
    "        self.dataset_size = len(self.image_paths)\n",
    "\n",
    "        if self.dataset_size == 0:\n",
    "            raise DataError(\"No images with the given file extension '{}' were found in the given image directories.\".format(image_file_extension))\n",
    "\n",
    "        if (not ground_truth_dirs is None) and (len(self.ground_truth_paths) != self.dataset_size):\n",
    "            raise DataError('Ground truth directories were given, but the number of ground truth images found does not match the number of images. Number of images: {}. Number of ground truth images: {}'.format(self.dataset_size, len(self.ground_truth_paths)))\n",
    "\n",
    "        if len(self.ground_truth_paths) > 0:\n",
    "            self.ground_truth = True\n",
    "\n",
    "    def get_num_files(self):\n",
    "        '''\n",
    "        Returns the total number of image files (or image/ground truth image file\n",
    "        pairs if ground truth data was given) contained in all dataset directories\n",
    "        passed to the BatchGenerator constructor.\n",
    "        '''\n",
    "        return self.dataset_size\n",
    "\n",
    "    def generate(self,\n",
    "                 batch_size,\n",
    "                 convert_colors_to_ids=False,\n",
    "                 convert_ids_to_ids=False,\n",
    "                 convert_to_one_hot=True,\n",
    "                 void_class_id=None,\n",
    "                 random_crop=False,\n",
    "                 crop=False,\n",
    "                 resize=False,\n",
    "                 brightness=False,\n",
    "                 flip=False,\n",
    "                 translate=False,\n",
    "                 scale=False,\n",
    "                 gray=False,\n",
    "                 to_disk=False,\n",
    "                 shuffle=True):\n",
    "        '''\n",
    "\n",
    "        With any of the image transformations below, the respective ground truth images, if given,\n",
    "        will be transformed accordingly.\n",
    "\n",
    "        Arguments:\n",
    "            batch_size (int): The number of images (or image/ground truth pairs) to generate per\n",
    "                batch.\n",
    "            convert_colors_to_ids (dict, optional): `False` or a dictionary in which the keys are\n",
    "                3-tuples of `dtype uint8` representing 3-channel color values and the values\n",
    "                are integers representing the segmentation class ID associated with a given color\n",
    "                value. If the input ground truth images are 3-channel color images and a conversion\n",
    "                dictionary is passed, the ground truth images will be converted to single-channel\n",
    "                images with the according class IDs instead of color values. It is recommended to\n",
    "                perform color-to-ID conversion offline.\n",
    "            convert_ids_to_ids (array or dict, optional): `False` or either a 1D Numpy array or a Python\n",
    "                dictionary that represents a map according to which the generator will convert the\n",
    "                grund truth data's current class IDs to the desired class IDs. In the case of an array,\n",
    "                the array's indices represent the current IDs and the array's integer values represent the\n",
    "                desired IDs to which to convert. The array must contain a map for all possible unique\n",
    "                current class IDs. In the case of a dictionary, both keys and values must be integers.\n",
    "                The keys are the current IDs and the values are the desired IDs to which to convert.\n",
    "                The dictionary does not need to contain a mapping for all possible unique current class IDs.\n",
    "                For conversion of all IDs, an array will enable much faster conversion than a dictionary.\n",
    "            convert_to_one_hot (bool, optional): If `True`, the ground truth data will be converted to\n",
    "                one-hot format.\n",
    "            void_class_id (int, optional): The class ID of a 'void' or 'background' class. Only relevant\n",
    "                if any of the `random_crop`, `translate`, or `scale` transformations are being used\n",
    "                on ground truth data. Determines the pixel value of blank image space that might occur\n",
    "                through the aforementioned transformations.\n",
    "            random_crop (tuple, optional): `False` or a tuple of two integers, `(height, width)`,\n",
    "                where `height` and `width` are the height and width of the patch that is to be cropped out at a random\n",
    "                position in the input image. Note that `height` and `width` can be arbitrary - they are allowed to be larger\n",
    "                than the image height and width, in which case the original image will be randomly placed on a black background\n",
    "                canvas of size `(height, width)`. Defaults to `False`.\n",
    "            crop (tuple, optional): `False` or a tuple of four integers, `(crop_top, crop_bottom, crop_left, crop_right)`,\n",
    "                with the number of pixels to crop off of each side of the images. Note: Cropping happens after random cropping.\n",
    "            resize (tuple, optional): `False` or a tuple of 2 integers for the desired output\n",
    "                size of the images in pixels. The expected format is `(height, width)`.\n",
    "                Note: Resizing happens after both random cropping and cropping.\n",
    "            brightness (tuple, optional): `False` or a tuple containing three floats, `(min, max, prob)`.\n",
    "                Scales the brightness of the image by a factor randomly picked from a uniform\n",
    "                distribution in the boundaries of `[min, max]`. Both min and max must be >=0.\n",
    "            flip (float, optional): `False` or a float in [0,1], see `prob` above. Flip the image horizontally.\n",
    "            translate (tuple, optional): `False` or a tuple, with the first two elements tuples containing\n",
    "                two integers each, and the third element a float: `((min, max), (min, max), prob)`.\n",
    "                The first tuple provides the range in pixels for the horizontal shift of the image,\n",
    "                the second tuple for the vertical shift. The number of pixels to shift the image\n",
    "                by is uniformly distributed within the boundaries of `[min, max]`, i.e. `min` is the number\n",
    "                of pixels by which the image is translated at least. Both `min` and `max` must be >=0.\n",
    "            scale (tuple, optional): `False` or a tuple containing three floats, `(min, max, prob)`.\n",
    "                Scales the image by a factor randomly picked from a uniform distribution in the boundaries\n",
    "                of `[min, max]`. Both `min` and `max` must be >=0.\n",
    "            gray (bool, optional): If `True`, converts the images to grayscale. Note that the resulting grayscale\n",
    "                images have shape `(height, width, 1)`.\n",
    "            to_disk (bool, optional): If `True`, the generated batches are being saved to `export_dir` (see constuctor)\n",
    "                in addition to being yielded. This can be used for offline dataset processing.\n",
    "            shuffle (bool, optional): If `True`, the dataset will be shuffled before each new pass.\n",
    "\n",
    "        Yields:\n",
    "            Either one 4D Numpy array of shape `(batch_size, img_height, img_with, num_channels)` with the\n",
    "            generated images, or, if paths to ground truth data were passed in the constructor, two Numpy\n",
    "            arrays, the first is the same as in the former case and the second has shape\n",
    "            `(batch_size, img_height, img_with)` and contains the generated ground truth images.\n",
    "        '''\n",
    "        if (convert_to_one_hot or (not convert_colors_to_ids is False) or (not convert_ids_to_ids is False)) and not self.ground_truth:\n",
    "            raise ValueError(\"Cannot convert ground truth data: No ground truth data given.\")\n",
    "\n",
    "        if convert_to_one_hot and self.num_classes is None:\n",
    "            raise ValueError(\"One-hot conversion requires that you pass an integer value for `num_classes` in the constructor, but `num_classes` is `None`.\")\n",
    "\n",
    "        if shuffle:\n",
    "            random.shuffle(self.image_paths)\n",
    "\n",
    "        current = 0\n",
    "\n",
    "        while True:\n",
    "\n",
    "            # Store the new batch here\n",
    "            images = []\n",
    "            gt_images = []\n",
    "\n",
    "            # Shuffle data after each complete pass\n",
    "            if current >= len(self.image_paths):\n",
    "                if shuffle: random.shuffle(self.image_paths)\n",
    "                current = 0\n",
    "\n",
    "            # Load the images and ground truth images for this batch\n",
    "            for image_path in self.image_paths[current:current+batch_size]: # Careful: This works in Python, but might cause an 'index out of bounds' error in other languages if `current+batch_size > len(image_paths)`\n",
    "\n",
    "                # Load the image\n",
    "                image = scipy.misc.imread(image_path)\n",
    "                img_height, img_width, img_ch = image.shape\n",
    "\n",
    "                # If at least one ground truth directory was given, load the ground truth images.\n",
    "                if self.ground_truth:\n",
    "\n",
    "                    gt_image_path = self.ground_truth_paths[os.path.basename(image_path)]\n",
    "                    gt_image = cv2.imread(gt_image_path,0)\n",
    "                    gt_dtype = gt_image.dtype\n",
    "\n",
    "                    if not convert_colors_to_ids is False:\n",
    "                        gt_image = convert_between_IDs_and_colors(gt_image, convert_colors_to_ids, gt_dtype=gt_dtype)\n",
    "\n",
    "                    if not convert_ids_to_ids is False:\n",
    "                        if isinstance(convert_ids_to_ids, np.ndarray):\n",
    "                            gt_image = convert_IDs_to_IDs(gt_image, convert_ids_to_ids)\n",
    "                        if isinstance(convert_ids_to_ids, dict):\n",
    "                            gt_image = convert_IDs_to_IDs_partial(gt_image, convert_ids_to_ids)\n",
    "\n",
    "                # Maybe process the images and ground truth images.\n",
    "\n",
    "                if random_crop:\n",
    "                    # Compute how much room we have in both dimensions to make a random crop.\n",
    "                    # A negative number here means that we want to crop out a patch that is larger than the original image in the respective dimension,\n",
    "                    # in which case we will create a black background canvas onto which we will randomly place the image.\n",
    "                    y_range = img_height - random_crop[0]\n",
    "                    x_range = img_width - random_crop[1]\n",
    "\n",
    "                    # Select a random crop position from the possible crop positions\n",
    "                    if y_range >= 0: crop_ymin = np.random.randint(0, y_range + 1) # There are y_range + 1 possible positions for the crop in the vertical dimension\n",
    "                    else: crop_ymin = np.random.randint(0, -y_range + 1) # The possible positions for the image on the background canvas in the vertical dimension\n",
    "                    if x_range >= 0: crop_xmin = np.random.randint(0, x_range + 1) # There are x_range + 1 possible positions for the crop in the horizontal dimension\n",
    "                    else: crop_xmin = np.random.randint(0, -x_range + 1) # The possible positions for the image on the background canvas in the horizontal dimension\n",
    "                    # Perform the crop\n",
    "                    if y_range >= 0 and x_range >= 0: # If the patch to be cropped out is smaller than the original image in both dimenstions, we just perform a regular crop\n",
    "                        # Crop the image\n",
    "                        image = np.copy(image[crop_ymin:crop_ymin+random_crop[0], crop_xmin:crop_xmin+random_crop[1]])\n",
    "                        # Do the same for the ground truth image.\n",
    "                        if self.ground_truth: gt_image = np.copy(gt_image[crop_ymin:crop_ymin+random_crop[0], crop_xmin:crop_xmin+random_crop[1]])\n",
    "                    elif y_range >= 0 and x_range < 0: # If the crop is larger than the original image in the horizontal dimension only,...\n",
    "                        # Crop the image\n",
    "                        patch_image = np.copy(image[crop_ymin:crop_ymin+random_crop[0]]) # ...crop the vertical dimension just as before,...\n",
    "                        canvas = np.zeros(shape=(random_crop[0], random_crop[1], patch_image.shape[2]), dtype=np.uint8) # ...generate a blank background image to place the patch onto,...\n",
    "                        canvas[:, crop_xmin:crop_xmin+img_width] = patch_image # ...and place the patch onto the canvas at the random `crop_xmin` position computed above.\n",
    "                        image = canvas\n",
    "                        # Do the same for the ground truth image.\n",
    "                        if self.ground_truth:\n",
    "                            patch_gt_image = np.copy(gt_image[crop_ymin:crop_ymin+random_crop[0]]) # ...crop the vertical dimension just as before,...\n",
    "                            canvas = np.full(shape=random_crop, fill_value=void_class_id, dtype=gt_dtype) # ...generate a blank background image to place the patch onto,...\n",
    "                            canvas[:, crop_xmin:crop_xmin+img_width] = patch_gt_image # ...and place the patch onto the canvas at the random `crop_xmin` position computed above.\n",
    "                            gt_image = canvas\n",
    "                    elif y_range < 0 and x_range >= 0: # If the crop is larger than the original image in the vertical dimension only,...\n",
    "                        # Crop the image\n",
    "                        patch_image = np.copy(image[:,crop_xmin:crop_xmin+random_crop[1]]) # ...crop the horizontal dimension just as in the first case,...\n",
    "                        canvas = np.zeros(shape=(random_crop[0], random_crop[1], patch_image.shape[2]), dtype=np.uint8) # ...generate a blank background image to place the patch onto,...\n",
    "                        canvas[crop_ymin:crop_ymin+img_height, :] = patch_image # ...and place the patch onto the canvas at the random `crop_ymin` position computed above.\n",
    "                        image = canvas\n",
    "                        # Do the same for the ground truth image.\n",
    "                        if self.ground_truth:\n",
    "                            patch_gt_image = np.copy(gt_image[:,crop_xmin:crop_xmin+random_crop[1]]) # ...crop the horizontal dimension just as in the first case,...\n",
    "                            canvas = np.full(shape=random_crop, fill_value=void_class_id, dtype=gt_dtype) # ...generate a blank background image to place the patch onto,...\n",
    "                            canvas[crop_ymin:crop_ymin+img_height, :] = patch_gt_image # ...and place the patch onto the canvas at the random `crop_ymin` position computed above.\n",
    "                            gt_image = canvas\n",
    "                    else:  # If the crop is larger than the original image in both dimensions,...\n",
    "                        patch_image = np.copy(image)\n",
    "                        canvas = np.zeros(shape=(random_crop[0], random_crop[1], patch_image.shape[2]), dtype=np.uint8) # ...generate a blank background image to place the patch onto,...\n",
    "                        canvas[crop_ymin:crop_ymin+img_height, crop_xmin:crop_xmin+img_width] = patch_image # ...and place the patch onto the canvas at the random `(crop_ymin, crop_xmin)` position computed above.\n",
    "                        image = canvas\n",
    "                        # Do the same for the ground truth image.\n",
    "                        if self.ground_truth:\n",
    "                            patch_gt_image = np.copy(gt_image)\n",
    "                            canvas = np.full(shape=random_crop, fill_value=void_class_id, dtype=gt_dtype) # ...generate a blank background image to place the patch onto,...\n",
    "                            canvas[crop_ymin:crop_ymin+img_height, crop_xmin:crop_xmin+img_width] = patch_gt_image # ...and place the patch onto the canvas at the random `(crop_ymin, crop_xmin)` position computed above.\n",
    "                            gt_image = canvas\n",
    "                    # Update the height and width values.\n",
    "                    img_height, img_width = random_crop\n",
    "\n",
    "                if crop:\n",
    "                    image = np.copy(image[crop[0]:img_height-crop[1], crop[2]:img_width-crop[3]])\n",
    "                    gt_image = np.copy(gt_image[crop[0]:img_height-crop[1], crop[2]:img_width-crop[3]])\n",
    "\n",
    "                if resize:\n",
    "                    image = cv2.resize(image, dsize=(resize[1], resize[0]), interpolation=cv2.INTER_LINEAR)\n",
    "                    if self.ground_truth: gt_image = cv2.resize(gt_image, dsize=(resize[1], resize[0]), interpolation=cv2.INTER_NEAREST)\n",
    "                    img_height, img_width = resize # Updating these at this point is unnecessary, but it's one fewer source of error if this method gets expanded in the future\n",
    "\n",
    "                if brightness:\n",
    "                    p = np.random.uniform(0,1)\n",
    "                    if p >= (1-brightness[2]):\n",
    "                        image = _brightness(image, min=brightness[0], max=brightness[1])\n",
    "\n",
    "                if flip:\n",
    "                    p = np.random.uniform(0,1)\n",
    "                    if p >= (1-flip):\n",
    "                        image = cv2.flip(image, 1) # Horizontal flip\n",
    "                        if self.ground_truth: gt_image = cv2.flip(gt_image, 1) # Horizontal flip\n",
    "\n",
    "                if translate:\n",
    "                    p = np.random.uniform(0,1)\n",
    "                    if p >= (1-translate[2]):\n",
    "                        # Randomly select horizontal and vertical shift values.\n",
    "                        x = np.random.randint(translate[0][0], translate[0][1]+1)\n",
    "                        y = np.random.randint(translate[1][0], translate[1][1]+1)\n",
    "                        x_shift = random.choice([-x, x])\n",
    "                        y_shift = random.choice([-y, y])\n",
    "                        # Compute the warping matrix for the selected values.\n",
    "                        translation_matrix = np.float32([[1,0,x_shift],[0,1,y_shift]])\n",
    "                        # Warp the image and maybe the ground truth image.\n",
    "                        image = cv2.warpAffine(src=image, M=translation_matrix, dsize=(img_width, img_height))\n",
    "                        if self.ground_truth: gt_image = cv2.warpAffine(src=gt_image, M=translation_matrix, dsize=(img_width, img_height), borderValue=void_class_id)\n",
    "\n",
    "                if scale:\n",
    "                    p = np.random.uniform(0,1)\n",
    "                    if p >= (1-scale[2]):\n",
    "                        scaling_factor = np.random.uniform(scale[0], scale[1])\n",
    "                        scaled_height = int(img_height * scaling_factor)\n",
    "                        scaled_width = int(img_width * scaling_factor)\n",
    "                        y_offset = abs(int((img_height - scaled_height) / 2))\n",
    "                        x_offset = abs(int((img_width - scaled_width) / 2))\n",
    "\n",
    "                        # Scale the image.\n",
    "                        patch_image = cv2.resize(image, dsize=(scaled_width, scaled_height), interpolation=cv2.INTER_LINEAR)\n",
    "                        if scaling_factor <= 1:\n",
    "                            canvas = np.zeros(shape=(img_height, img_width, img_ch), dtype=np.uint8)\n",
    "                            canvas[y_offset:y_offset+scaled_height, x_offset:x_offset+scaled_width] = patch_image\n",
    "                            image = canvas\n",
    "                        if scaling_factor > 1:\n",
    "                            image = np.copy(patch_image[y_offset:img_height+y_offset, x_offset:img_width+x_offset])\n",
    "\n",
    "                        # Scale the ground truth image.\n",
    "                        if self.ground_truth:\n",
    "                            patch_gt_image = cv2.resize(gt_image, dsize=(scaled_width, scaled_height), interpolation=cv2.INTER_NEAREST)\n",
    "                            if scaling_factor <= 1:\n",
    "                                canvas = np.full(shape=(img_height, img_width), fill_value=void_class_id, dtype=gt_dtype)\n",
    "                                canvas[y_offset:y_offset+scaled_height, x_offset:x_offset+scaled_width] = patch_gt_image\n",
    "                                gt_image = canvas\n",
    "                            if scaling_factor > 1:\n",
    "                                gt_image = np.copy(patch_gt_image[y_offset:img_height+y_offset, x_offset:img_width+x_offset])\n",
    "\n",
    "                if gray:\n",
    "                    image = np.expand_dims(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY), axis=2)\n",
    "\n",
    "                # Maybe convert ground truth IDs to one-hot.\n",
    "                if convert_to_one_hot:\n",
    "                    gt_image = convert_IDs_to_one_hot(gt_image, self.num_classes)\n",
    "\n",
    "                if to_disk: # If the processed data is to be written to disk instead of yieled.\n",
    "                    # Create the directory (including parents) if it doesn't already exist.\n",
    "                    image_save_file_path = os.path.join(self.export_dir, os.path.relpath(image_path, start=self.root_dir))\n",
    "                    image_save_directory_path = os.path.dirname(image_save_file_path)\n",
    "                    pathlib.Path(image_save_directory_path).mkdir(parents=True, exist_ok=True)\n",
    "                    # Save the image.\n",
    "                    scipy.misc.imsave(image_save_file_path, image)\n",
    "                    if self.ground_truth:\n",
    "                        # Create the directory (including parents) if it doesn't already exist.\n",
    "                        gt_image_save_file_path = os.path.join(self.export_dir, os.path.relpath(gt_image_path, start=self.root_dir))\n",
    "                        gt_image_save_directory_path = os.path.dirname(gt_image_save_file_path)\n",
    "                        pathlib.Path(gt_image_save_directory_path).mkdir(parents=True, exist_ok=True)\n",
    "                        # Save the ground truth image.\n",
    "                        scipy.misc.imsave(gt_image_save_file_path, gt_image)\n",
    "\n",
    "                # Append the processed image (and maybe ground truth image) to this batch.\n",
    "                images.append(image)\n",
    "                if self.ground_truth: gt_images.append(gt_image)\n",
    "\n",
    "            current += batch_size\n",
    "\n",
    "            if self.ground_truth:\n",
    "                yield np.array(images), np.array(gt_images)\n",
    "            else:\n",
    "                yield np.array(images)\n",
    "\n",
    "    def process_all(self,\n",
    "                    convert_colors_to_ids=False,\n",
    "                    convert_ids_to_ids=False,\n",
    "                    convert_to_one_hot=False,\n",
    "                    void_class_id=None,\n",
    "                    random_crop=False,\n",
    "                    crop=False,\n",
    "                    resize=False,\n",
    "                    brightness=False,\n",
    "                    flip=False,\n",
    "                    translate=False,\n",
    "                    scale=False,\n",
    "                    gray=False,\n",
    "                    to_disk=True,\n",
    "                    shuffle=False,\n",
    "                    batch_size=1):\n",
    "        '''\n",
    "        Processes the entire dataset in batches of `batch_size` and saves the\n",
    "        results to `export_dir` (see constructor).\n",
    "\n",
    "        This is basically just a wrapper around the `generate()` method that\n",
    "        iterates over the entire dataset (or datasets, in case multiple were\n",
    "        passed in the constructor).\n",
    "\n",
    "        For documentation of the arguments, see `generate()`. Returns void.\n",
    "        '''\n",
    "\n",
    "        preprocessor = self.generate(batch_size=batch_size,\n",
    "                                convert_colors_to_ids=convert_colors_to_ids,\n",
    "                                convert_ids_to_ids=convert_ids_to_ids,\n",
    "                                convert_to_one_hot=convert_to_one_hot,\n",
    "                                void_class_id=void_class_id,\n",
    "                                random_crop=random_crop,\n",
    "                                crop=crop,\n",
    "                                resize=resize,\n",
    "                                brightness=brightness,\n",
    "                                flip=flip,\n",
    "                                translate=translate,\n",
    "                                scale=scale,\n",
    "                                gray=gray,\n",
    "                                to_disk=to_disk,\n",
    "                                shuffle=shuffle)\n",
    "\n",
    "        num_batches = ceil(self.dataset_size/batch_size)\n",
    "\n",
    "        tr = trange(num_batches, file=sys.stdout)\n",
    "        tr.set_description('Processing images')\n",
    "\n",
    "        for batch in tr:\n",
    "                next(preprocessor)\n",
    "\n",
    "\n",
    "def _brightness(image, min=0.5, max=2.0):\n",
    "    '''\n",
    "    Randomly changes the brightness of the input image.\n",
    "\n",
    "    Protected against overflow.\n",
    "    '''\n",
    "    hsv = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    random_br = np.random.uniform(min,max)\n",
    "\n",
    "    #To protect against overflow: Calculate a mask for all pixels\n",
    "    #where adjustment of the brightness would exceed the maximum\n",
    "    #brightness value and set the value to the maximum at those pixels.\n",
    "    mask = hsv[:,:,2] * random_br > 255\n",
    "    v_channel = np.where(mask, 255, hsv[:,:,2] * random_br)\n",
    "    hsv[:,:,2] = v_channel\n",
    "\n",
    "    return cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n",
    "\n",
    "class DataError(Exception):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    def __str__(self):\n",
    "        return repr(self.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
